{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOd09ZQUSayDU2c/ZFD1zX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abrazacs/Anylogic_trial/blob/master/lightning_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yorhd_0i-jfo"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchmetrics import Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "class MultyLayerPerceptron(pl.LightningModule):\n",
        "  def __init__(self, image_shape = (1, 28, 28), hidden_units=(32, 16)):\n",
        "    super().__init__()\n",
        "    self.train_acc = Accuracy(task='multiclass', num_classes=10)\n",
        "    self.valid_acc = Accuracy(task='multiclass', num_classes=10)\n",
        "    self.test_acc = Accuracy(task='multiclass', num_classes=10)\n",
        "\n",
        "    input_size = image_shape[0]*image_shape[1]*image_shape[2]\n",
        "    all_layers = [nn.Flatten()]\n",
        "    for hidden_unit in hidden_units:\n",
        "      layer = nn.Linear(input_size, hidden_unit)\n",
        "      all_layers.append(layer)\n",
        "      all_layers.append(nn.ReLU())\n",
        "      input_size = hidden_unit\n",
        "\n",
        "    all_layers.append(nn.Linear(hidden_units[-1], 10))\n",
        "    self.layers = nn.Sequential(*all_layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layers(x)\n",
        "    return x\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    logits = self(x)\n",
        "    loss = nn.functional.cross_entropy(logits, y)\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    self.train_acc.update(preds, y)\n",
        "    self.log(\"train_loss\", loss, prog_bar=True)\n",
        "    return loss\n",
        "\n",
        "  def on_train_epoch_end(self):\n",
        "    self.log(\"train_acc_epoch\", self.train_acc.compute(), prog_bar=True)\n",
        "    self.train_acc.reset()\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    logits = self(x)\n",
        "    loss = nn.functional.cross_entropy(logits, y)\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    self.valid_acc.update(preds, y)\n",
        "    self.log(\"valid_loss\", loss, prog_bar=True)\n",
        "    return loss\n",
        "\n",
        "  def on_validation_epoch_end(self):\n",
        "    self.log(\"valid_acc_epoch\", self.valid_acc.compute(), prog_bar=True)\n",
        "    self.valid_acc.reset()\n",
        "\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    logits = self(x)\n",
        "    loss = nn.functional.cross_entropy(logits, y)\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    self.test_acc.update(preds, y)\n",
        "    self.log(\"test_loss\", loss, prog_bar=True)\n",
        "    return loss\n",
        "\n",
        "  def on_test_epoch_end(self):\n",
        "    self.log(\"test_acc_epoch\", self.test_acc.compute(), prog_bar=True)\n",
        "    self.test_acc.reset()\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "zlkItZJK_QKB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "class MnistDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, data_path='./'):\n",
        "    super().__init__()\n",
        "    self.data_path = data_path\n",
        "    self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "  def prepare_data(self):\n",
        "    MNIST(root=self.data_path, download=True)\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "    mnist = MNIST(root=self.data_path, train=True, transform=self.transform)\n",
        "    self.train_set, self.valid_set = random_split(\n",
        "        mnist, [55000, 5000], generator=torch.Generator().manual_seed(1)\n",
        "    )\n",
        "    self.test_set = MNIST(root=self.data_path, train=False, transform=self.transform)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_set, batch_size=64, num_workers=4)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.valid_set, batch_size=64, num_workers=4)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.test_set, batch_size=64, num_workers=4)"
      ],
      "metadata": {
        "id": "WBB594klC3sY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "mnist_dm = MnistDataModule()\n",
        "mnist_classifier = MultyLayerPerceptron()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  trainer = pl.Trainer(max_epochs=10, gpus=1)\n",
        "else:\n",
        "  trainer = pl.Trainer(max_epochs=10)\n",
        "\n",
        "trainer.fit(model=mnist_classifier, datamodule=mnist_dm)\n"
      ],
      "metadata": {
        "id": "Mo1KHP3EEMpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs"
      ],
      "metadata": {
        "id": "o_JXBWsvGtUu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}